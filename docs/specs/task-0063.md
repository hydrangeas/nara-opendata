# 0063: バックアップとリストア手順の確立

## 説明
システムの重要データ（データベース、設定ファイル、ログ、静的ファイル）のバックアップとリストア手順を確立する。定期バックアップの自動化、バックアップデータの検証、迅速なリストア手順、災害復旧計画を含む包括的なデータ保護戦略を実装する。

## タスク種別
- [ ] 機能実装
- [ ] バグ修正
- [ ] リファクタリング
- [ ] テスト
- [x] ドキュメント
- [ ] 調査

## 優先度
中

## 見積もり工数
[ストーリーポイント: 2] (約0.5日)

## 依存関係
- 前提タスク: #0003, #0024, #0059
- 関連タスク: #0066

## 受け入れ基準
- [ ] バックアップ対象が明確に定義されている
- [ ] 自動バックアップスクリプトが作成されている
- [ ] バックアップデータの整合性チェックが実装されている
- [ ] リストア手順が文書化されている
- [ ] リストアのテストが実施されている
- [ ] バックアップのスケジュールが設定されている
- [ ] バックアップデータの保管期間とローテーションが定義されている
- [ ] 災害復旧計画（DRP）が文書化されている

## 技術的な詳細
### バックアップ対象の定義
```yaml
# backup/backup-config.yml
backup_targets:
  # Supabaseデータベース
  database:
    type: postgresql
    connection: ${SUPABASE_DB_URL}
    tables:
      - auth_logs
      - api_logs
      - rate_limit_logs
    backup_method: pg_dump
    compression: gzip
    
  # アプリケーション設定
  configurations:
    paths:
      - /app/.env.production
      - /app/config/
    exclude:
      - "*.local"
      - "*.tmp"
    
  # 静的データファイル
  data_files:
    paths:
      - /data/secure/
      - /data/public/
    compression: tar.gz
    
  # アプリケーションログ
  logs:
    paths:
      - /app/logs/
    retention: 30 # 30日分のみバックアップ
    compression: gzip

# バックアップスケジュール
schedules:
  daily:
    time: "02:00"
    targets: [database, logs]
    retention: 7 # 7日分保持
    
  weekly:
    time: "Sunday 03:00"
    targets: [database, configurations, data_files, logs]
    retention: 4 # 4週間分保持
    
  monthly:
    time: "1st day 04:00"
    targets: [database, configurations, data_files]
    retention: 12 # 12ヶ月分保持

# バックアップ先
destinations:
  primary:
    type: s3
    bucket: ${BACKUP_S3_BUCKET}
    region: ap-northeast-1
    encryption: AES256
    
  secondary:
    type: gcs
    bucket: ${BACKUP_GCS_BUCKET}
    location: asia-northeast1
```

### 自動バックアップスクリプト
```bash
#!/bin/bash
# scripts/backup/automated-backup.sh

set -euo pipefail

# 設定読み込み
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "${SCRIPT_DIR}/backup-env.sh"

# ログ設定
LOG_FILE="/var/log/backup/backup-$(date +%Y%m%d-%H%M%S).log"
exec 1> >(tee -a "${LOG_FILE}")
exec 2>&1

echo "[$(date)] Starting backup process..."

# バックアップディレクトリ作成
BACKUP_DATE=$(date +%Y%m%d-%H%M%S)
BACKUP_DIR="/tmp/backup/${BACKUP_DATE}"
mkdir -p "${BACKUP_DIR}"

# 1. データベースバックアップ
backup_database() {
    echo "[$(date)] Backing up database..."
    
    # Supabaseデータベースのバックアップ
    PGPASSWORD="${SUPABASE_DB_PASSWORD}" pg_dump \
        -h "${SUPABASE_DB_HOST}" \
        -p "${SUPABASE_DB_PORT}" \
        -U "${SUPABASE_DB_USER}" \
        -d "${SUPABASE_DB_NAME}" \
        -t auth_logs \
        -t api_logs \
        -t rate_limit_logs \
        --no-owner \
        --no-privileges \
        --if-exists \
        --clean \
        | gzip > "${BACKUP_DIR}/database-${BACKUP_DATE}.sql.gz"
    
    # チェックサム生成
    sha256sum "${BACKUP_DIR}/database-${BACKUP_DATE}.sql.gz" > "${BACKUP_DIR}/database-${BACKUP_DATE}.sql.gz.sha256"
    
    echo "[$(date)] Database backup completed"
}

# 2. 設定ファイルバックアップ
backup_configurations() {
    echo "[$(date)] Backing up configurations..."
    
    tar czf "${BACKUP_DIR}/configs-${BACKUP_DATE}.tar.gz" \
        --exclude="*.local" \
        --exclude="*.tmp" \
        -C /app \
        .env.production \
        config/
    
    sha256sum "${BACKUP_DIR}/configs-${BACKUP_DATE}.tar.gz" > "${BACKUP_DIR}/configs-${BACKUP_DATE}.tar.gz.sha256"
    
    echo "[$(date)] Configuration backup completed"
}

# 3. データファイルバックアップ
backup_data_files() {
    echo "[$(date)] Backing up data files..."
    
    # データファイルの増分バックアップ
    if [ -f "/var/backup/last-data-backup.snar" ]; then
        tar czf "${BACKUP_DIR}/data-${BACKUP_DATE}-incremental.tar.gz" \
            --listed-incremental="/var/backup/last-data-backup.snar" \
            -C / \
            data/secure/ \
            data/public/
    else
        tar czf "${BACKUP_DIR}/data-${BACKUP_DATE}-full.tar.gz" \
            --listed-incremental="/var/backup/last-data-backup.snar" \
            -C / \
            data/secure/ \
            data/public/
    fi
    
    sha256sum "${BACKUP_DIR}/data-"*.tar.gz > "${BACKUP_DIR}/data-checksums.sha256"
    
    echo "[$(date)] Data files backup completed"
}

# 4. ログファイルバックアップ
backup_logs() {
    echo "[$(date)] Backing up logs..."
    
    # 過去24時間のログのみバックアップ
    find /app/logs -name "*.log" -mtime -1 -print0 | \
        tar czf "${BACKUP_DIR}/logs-${BACKUP_DATE}.tar.gz" --null -T -
    
    echo "[$(date)] Logs backup completed"
}

# 5. S3へのアップロード
upload_to_s3() {
    echo "[$(date)] Uploading to S3..."
    
    aws s3 sync "${BACKUP_DIR}" "s3://${BACKUP_S3_BUCKET}/${BACKUP_TYPE}/${BACKUP_DATE}/" \
        --storage-class STANDARD_IA \
        --server-side-encryption AES256
    
    # メタデータの記録
    cat > "${BACKUP_DIR}/metadata.json" <<EOF
{
    "backup_date": "${BACKUP_DATE}",
    "backup_type": "${BACKUP_TYPE}",
    "backup_size": "$(du -sh ${BACKUP_DIR} | cut -f1)",
    "files": $(ls -1 ${BACKUP_DIR} | jq -R -s -c 'split("\n")[:-1]'),
    "retention_days": ${RETENTION_DAYS}
}
EOF
    
    aws s3 cp "${BACKUP_DIR}/metadata.json" "s3://${BACKUP_S3_BUCKET}/${BACKUP_TYPE}/${BACKUP_DATE}/"
    
    echo "[$(date)] S3 upload completed"
}

# 6. 古いバックアップの削除
cleanup_old_backups() {
    echo "[$(date)] Cleaning up old backups..."
    
    # S3から古いバックアップを削除
    CUTOFF_DATE=$(date -d "${RETENTION_DAYS} days ago" +%Y%m%d)
    
    aws s3 ls "s3://${BACKUP_S3_BUCKET}/${BACKUP_TYPE}/" | \
        awk '{print $2}' | \
        while read dir; do
            dir_date=$(echo $dir | grep -oE '[0-9]{8}' | head -1)
            if [[ $dir_date -lt $CUTOFF_DATE ]]; then
                echo "Deleting old backup: $dir"
                aws s3 rm "s3://${BACKUP_S3_BUCKET}/${BACKUP_TYPE}/${dir}" --recursive
            fi
        done
    
    echo "[$(date)] Cleanup completed"
}

# メイン処理
main() {
    # バックアップタイプの判定
    BACKUP_TYPE="${1:-daily}"
    
    case "${BACKUP_TYPE}" in
        daily)
            RETENTION_DAYS=7
            backup_database
            backup_logs
            ;;
        weekly)
            RETENTION_DAYS=28
            backup_database
            backup_configurations
            backup_data_files
            backup_logs
            ;;
        monthly)
            RETENTION_DAYS=365
            backup_database
            backup_configurations
            backup_data_files
            ;;
        *)
            echo "Unknown backup type: ${BACKUP_TYPE}"
            exit 1
            ;;
    esac
    
    # アップロードと後処理
    upload_to_s3
    cleanup_old_backups
    
    # 一時ファイルの削除
    rm -rf "${BACKUP_DIR}"
    
    echo "[$(date)] Backup process completed successfully"
    
    # 監視システムへの通知
    curl -X POST "${MONITORING_WEBHOOK}" \
        -H "Content-Type: application/json" \
        -d "{\"status\": \"success\", \"type\": \"${BACKUP_TYPE}\", \"date\": \"${BACKUP_DATE}\"}"
}

# エラーハンドリング
trap 'echo "[$(date)] Backup failed: $?"; curl -X POST "${MONITORING_WEBHOOK}" -H "Content-Type: application/json" -d "{\"status\": \"failed\", \"type\": \"${BACKUP_TYPE}\", \"date\": \"${BACKUP_DATE}\"}"' ERR

# 実行
main "$@"
```

### リストアスクリプト
```bash
#!/bin/bash
# scripts/backup/restore.sh

set -euo pipefail

# 使用方法の表示
usage() {
    cat <<EOF
Usage: $0 [OPTIONS]
Options:
    -d, --date YYYYMMDD-HHMMSS    Backup date to restore
    -t, --type TYPE                Backup type (daily/weekly/monthly)
    -c, --component COMPONENT      Component to restore (database/configs/data/logs/all)
    -y, --yes                      Skip confirmation
    -h, --help                     Show this help message
EOF
    exit 1
}

# パラメータ解析
BACKUP_DATE=""
BACKUP_TYPE="daily"
COMPONENT="all"
SKIP_CONFIRM=false

while [[ $# -gt 0 ]]; do
    case $1 in
        -d|--date) BACKUP_DATE="$2"; shift 2 ;;
        -t|--type) BACKUP_TYPE="$2"; shift 2 ;;
        -c|--component) COMPONENT="$2"; shift 2 ;;
        -y|--yes) SKIP_CONFIRM=true; shift ;;
        -h|--help) usage ;;
        *) echo "Unknown option: $1"; usage ;;
    esac
done

if [ -z "$BACKUP_DATE" ]; then
    echo "Error: Backup date is required"
    usage
fi

# リストア確認
if [ "$SKIP_CONFIRM" = false ]; then
    echo "WARNING: This will restore data from backup ${BACKUP_DATE}"
    echo "Component: ${COMPONENT}"
    echo "Type: ${BACKUP_TYPE}"
    read -p "Are you sure? (yes/no): " confirm
    if [ "$confirm" != "yes" ]; then
        echo "Restore cancelled"
        exit 0
    fi
fi

# リストア実行
RESTORE_DIR="/tmp/restore/${BACKUP_DATE}"
mkdir -p "${RESTORE_DIR}"

echo "[$(date)] Downloading backup from S3..."
aws s3 sync "s3://${BACKUP_S3_BUCKET}/${BACKUP_TYPE}/${BACKUP_DATE}/" "${RESTORE_DIR}/"

# チェックサム検証
echo "[$(date)] Verifying checksums..."
cd "${RESTORE_DIR}"
sha256sum -c *.sha256

# コンポーネント別リストア
case "${COMPONENT}" in
    database)
        echo "[$(date)] Restoring database..."
        gunzip -c "database-${BACKUP_DATE}.sql.gz" | \
            PGPASSWORD="${SUPABASE_DB_PASSWORD}" psql \
                -h "${SUPABASE_DB_HOST}" \
                -p "${SUPABASE_DB_PORT}" \
                -U "${SUPABASE_DB_USER}" \
                -d "${SUPABASE_DB_NAME}"
        ;;
    configs)
        echo "[$(date)] Restoring configurations..."
        tar xzf "configs-${BACKUP_DATE}.tar.gz" -C /app/
        ;;
    data)
        echo "[$(date)] Restoring data files..."
        tar xzf "data-${BACKUP_DATE}"*.tar.gz -C /
        ;;
    logs)
        echo "[$(date)] Restoring logs..."
        tar xzf "logs-${BACKUP_DATE}.tar.gz" -C /app/logs/
        ;;
    all)
        # すべてのコンポーネントをリストア
        $0 -d "$BACKUP_DATE" -t "$BACKUP_TYPE" -c database -y
        $0 -d "$BACKUP_DATE" -t "$BACKUP_TYPE" -c configs -y
        $0 -d "$BACKUP_DATE" -t "$BACKUP_TYPE" -c data -y
        $0 -d "$BACKUP_DATE" -t "$BACKUP_TYPE" -c logs -y
        ;;
    *)
        echo "Unknown component: ${COMPONENT}"
        exit 1
        ;;
esac

# クリーンアップ
rm -rf "${RESTORE_DIR}"

echo "[$(date)] Restore completed successfully"
```

### 災害復旧計画（DRP）
```markdown
# 災害復旧計画（Disaster Recovery Plan）

## 1. 目的と範囲

本計画は、Open Data APIシステムにおける災害や障害発生時の復旧手順を定義し、ビジネス継続性を確保することを目的とする。

## 2. 復旧目標

- **RTO (Recovery Time Objective)**: 4時間
- **RPO (Recovery Point Objective)**: 24時間

## 3. 災害シナリオと対応

### 3.1 データベース障害
**症状**: Supabaseデータベースへの接続不可
**対応手順**:
1. Supabaseステータスページで障害情報を確認
2. 一時的な読み取り専用モードへの切り替え
3. 最新のデータベースバックアップからリストア
4. データ整合性の確認

### 3.2 アプリケーション障害
**症状**: APIサービスの応答なし
**対応手順**:
1. Vercelダッシュボードで状態確認
2. 前のデプロイメントへのロールバック
3. ログ分析による原因特定
4. 修正版のデプロイ

### 3.3 データ損失
**症状**: ファイルやデータの消失
**対応手順**:
1. 損失範囲の特定
2. 最新のバックアップから該当データをリストア
3. 差分データの手動復旧（可能な場合）
4. データ検証とテスト

## 4. 復旧手順

### Phase 1: 初期対応（0-30分）
1. インシデントの検知と確認
2. 影響範囲の評価
3. ステークホルダーへの通知
4. 一時的な対策の実施

### Phase 2: 復旧作業（30分-3時間）
1. 復旧計画の決定
2. バックアップからのリストア実行
3. システムの再起動と検証
4. 基本機能の確認

### Phase 3: 完全復旧（3-4時間）
1. 全機能の動作確認
2. パフォーマンステスト
3. ユーザーへの復旧通知
4. インシデントレポートの作成

## 5. 連絡体制

- **インシデント管理者**: [担当者名]
- **技術リード**: [担当者名]
- **ステークホルダー連絡**: [担当者名]

## 6. テスト計画

- 四半期ごとのリストアテスト実施
- 年次の完全災害復旧訓練
- バックアップデータの定期検証
```

### バックアップ監視スクリプト
```typescript
// scripts/backup/monitor-backup.ts
import { S3Client, ListObjectsV2Command } from '@aws-sdk/client-s3';
import { createLogger } from '@/logging/logger';

const logger = createLogger('backup-monitor');

interface BackupStatus {
  type: string;
  lastBackup: Date | null;
  isHealthy: boolean;
  message: string;
}

export async function checkBackupHealth(): Promise<BackupStatus[]> {
  const s3Client = new S3Client({ region: process.env.AWS_REGION });
  const bucket = process.env.BACKUP_S3_BUCKET!;
  const results: BackupStatus[] = [];

  const backupTypes = ['daily', 'weekly', 'monthly'];
  const expectedIntervals = {
    daily: 24 * 60 * 60 * 1000, // 24時間
    weekly: 7 * 24 * 60 * 60 * 1000, // 7日
    monthly: 30 * 24 * 60 * 60 * 1000, // 30日
  };

  for (const type of backupTypes) {
    try {
      const command = new ListObjectsV2Command({
        Bucket: bucket,
        Prefix: `${type}/`,
        MaxKeys: 1000,
      });

      const response = await s3Client.send(command);
      const backups = response.Contents || [];

      // 最新のバックアップを取得
      const latestBackup = backups
        .filter(obj => obj.Key?.includes('metadata.json'))
        .sort((a, b) => (b.LastModified?.getTime() || 0) - (a.LastModified?.getTime() || 0))[0];

      if (!latestBackup || !latestBackup.LastModified) {
        results.push({
          type,
          lastBackup: null,
          isHealthy: false,
          message: 'No backup found',
        });
        continue;
      }

      const timeSinceLastBackup = Date.now() - latestBackup.LastModified.getTime();
      const isHealthy = timeSinceLastBackup <= expectedIntervals[type] * 1.5; // 50%の余裕を持たせる

      results.push({
        type,
        lastBackup: latestBackup.LastModified,
        isHealthy,
        message: isHealthy 
          ? 'Backup is up to date' 
          : `Last backup is ${Math.floor(timeSinceLastBackup / (60 * 60 * 1000))} hours old`,
      });

    } catch (error) {
      logger.error(`Failed to check ${type} backup health`, error);
      results.push({
        type,
        lastBackup: null,
        isHealthy: false,
        message: `Error: ${error.message}`,
      });
    }
  }

  return results;
}

// 定期実行
if (require.main === module) {
  checkBackupHealth()
    .then(results => {
      console.log('Backup Health Check Results:');
      results.forEach(result => {
        console.log(`${result.type}: ${result.isHealthy ? '✓' : '✗'} - ${result.message}`);
      });
    })
    .catch(error => {
      console.error('Backup health check failed:', error);
      process.exit(1);
    });
}
```