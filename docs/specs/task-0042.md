# 0042: レート制限ログのリアルタイム記録と集計

## 説明

APIアクセスのレート制限ログをリアルタイムで記録し、ウィンドウごとの集計を行う機能の実装。スライディングウィンドウ方式での集計、ユーザーティアごとの制限管理、パフォーマンスを考慮したバッチ処理を含む。

## タスク種別

- [x] 機能実装
- [ ] バグ修正
- [ ] リファクタリング
- [ ] テスト
- [ ] ドキュメント
- [ ] 調査

## 優先度

高

## 見積もり工数

[ストーリーポイント: 3] (約1日)

## 依存関係

- 前提タスク: #0021, #0022, #0040
- 関連タスク: #0023, #0043

## 受け入れ基準

- [ ] レート制限ログがリアルタイムで記録される
- [ ] スライディングウィンドウでの集計が正確
- [ ] バッチ処理による効率的な記録
- [ ] 並行アクセスでの整合性が保たれる
- [ ] 古いログの自動削除が動作する
- [ ] 集計クエリのパフォーマンスが良好
- [ ] 単体テストと負荷テストが作成されている
- [ ] モニタリング用のメトリクスが出力される

## 技術的な詳細

### レート制限ログサービス

```typescript
// src/infrastructure/services/rate-limit-log.service.ts
import { injectable, inject } from 'tsyringe';
import { IRateLimitLogService } from '@/domain/api/interfaces/rate-limit-log.interface';
import { UserId } from '@/domain/auth/value-objects/user-id';
import { UserTier } from '@/domain/auth/value-objects/user-tier';
import { Result } from '@/domain/shared/result';
import { DomainError } from '@/domain/errors/domain-error';
import { SupabaseClient } from '@supabase/supabase-js';
import { DI_TOKENS } from '@/infrastructure/di/tokens';
import { Logger } from 'pino';
import PQueue from 'p-queue';

interface RateLimitWindow {
  userId: string;
  endpoint: string;
  windowStart: Date;
  requestCount: number;
  tier: string;
}

interface RateLimitResult {
  allowed: boolean;
  limit: number;
  remaining: number;
  resetAt: Date;
}

@injectable()
export class RateLimitLogService implements IRateLimitLogService {
  private readonly windowSizeMs = 60 * 1000; // 1分
  private readonly batchQueue: PQueue;
  private readonly pendingLogs: Map<string, RateLimitWindow>;
  private batchTimer?: NodeJS.Timeout;

  constructor(
    @inject(DI_TOKENS.SupabaseClient)
    private readonly supabase: SupabaseClient,
    @inject(DI_TOKENS.Logger)
    private readonly logger: Logger,
  ) {
    this.batchQueue = new PQueue({ concurrency: 5 });
    this.pendingLogs = new Map();
    this.startBatchProcessor();
  }

  async checkAndLog(
    userId: UserId,
    endpoint: string,
    tier: UserTier,
  ): Promise<Result<RateLimitResult, DomainError>> {
    try {
      const now = new Date();
      const windowStart = this.getWindowStart(now);
      const limit = tier.getRateLimit();

      // 現在のウィンドウでのリクエスト数を取得
      const countResult = await this.getRequestCount(userId.value, endpoint, windowStart);

      if (countResult.isFailure) {
        return Result.fail(countResult.getError());
      }

      const currentCount = countResult.getValue();
      const allowed = currentCount < limit;
      const remaining = Math.max(0, limit - currentCount - 1);
      const resetAt = new Date(windowStart.getTime() + this.windowSizeMs);

      if (allowed) {
        // バッチキューに追加
        this.addToBatch({
          userId: userId.value,
          endpoint,
          windowStart,
          requestCount: 1,
          tier: tier.level,
        });
      }

      return Result.ok({
        allowed,
        limit,
        remaining,
        resetAt,
      });
    } catch (error) {
      this.logger.error({ error, userId: userId.value, endpoint }, 'Failed to check rate limit');

      return Result.fail(
        new DomainError('RATE_LIMIT_CHECK_ERROR', 'Failed to check rate limit', 'INTERNAL'),
      );
    }
  }

  async getUsageStats(
    userId: UserId,
    timeRange: { start: Date; end: Date },
  ): Promise<Result<Map<string, number>, DomainError>> {
    try {
      const { data, error } = await this.supabase
        .from('rate_limit_logs')
        .select('endpoint, request_count')
        .eq('user_id', userId.value)
        .gte('window_start', timeRange.start.toISOString())
        .lte('window_start', timeRange.end.toISOString());

      if (error) {
        return Result.fail(
          new DomainError('FETCH_STATS_ERROR', 'Failed to fetch usage statistics', 'INTERNAL'),
        );
      }

      // エンドポイントごとに集計
      const stats = new Map<string, number>();
      for (const record of data || []) {
        const current = stats.get(record.endpoint) || 0;
        stats.set(record.endpoint, current + record.request_count);
      }

      return Result.ok(stats);
    } catch (error) {
      return Result.fail(
        new DomainError('STATS_ERROR', 'Failed to calculate usage statistics', 'INTERNAL'),
      );
    }
  }

  private async getRequestCount(
    userId: string,
    endpoint: string,
    windowStart: Date,
  ): Promise<Result<number, DomainError>> {
    try {
      // メモリキャッシュをチェック
      const cacheKey = `${userId}:${endpoint}:${windowStart.getTime()}`;
      const pending = this.pendingLogs.get(cacheKey);

      // データベースから取得
      const { data, error } = await this.supabase
        .from('rate_limit_logs')
        .select('request_count')
        .eq('user_id', userId)
        .eq('endpoint', endpoint)
        .eq('window_start', windowStart.toISOString())
        .single();

      if (error && error.code !== 'PGRST116') {
        // Not found以外のエラー
        return Result.fail(
          new DomainError('COUNT_FETCH_ERROR', 'Failed to fetch request count', 'INTERNAL'),
        );
      }

      const dbCount = data?.request_count || 0;
      const pendingCount = pending?.requestCount || 0;

      return Result.ok(dbCount + pendingCount);
    } catch (error) {
      return Result.fail(new DomainError('COUNT_ERROR', 'Failed to get request count', 'INTERNAL'));
    }
  }

  private getWindowStart(timestamp: Date): Date {
    const ms = timestamp.getTime();
    const windowStart = Math.floor(ms / this.windowSizeMs) * this.windowSizeMs;
    return new Date(windowStart);
  }

  private addToBatch(log: RateLimitWindow): void {
    const key = `${log.userId}:${log.endpoint}:${log.windowStart.getTime()}`;
    const existing = this.pendingLogs.get(key);

    if (existing) {
      existing.requestCount += log.requestCount;
    } else {
      this.pendingLogs.set(key, { ...log });
    }
  }

  private startBatchProcessor(): void {
    // 100msごとにバッチ処理
    this.batchTimer = setInterval(() => {
      if (this.pendingLogs.size > 0) {
        this.processBatch();
      }
    }, 100);
  }

  private async processBatch(): Promise<void> {
    const logs = Array.from(this.pendingLogs.values());
    this.pendingLogs.clear();

    if (logs.length === 0) return;

    await this.batchQueue.add(async () => {
      try {
        // UPSERT操作でバッチ更新
        const { error } = await this.supabase.from('rate_limit_logs').upsert(
          logs.map((log) => ({
            user_id: log.userId,
            identifier: log.userId,
            endpoint: log.endpoint,
            window_start: log.windowStart.toISOString(),
            request_count: log.requestCount,
            tier: log.tier,
          })),
          {
            onConflict: 'user_id,endpoint,window_start',
            count: 'exact',
          },
        );

        if (error) {
          this.logger.error(
            { error, logCount: logs.length },
            'Failed to batch insert rate limit logs',
          );

          // 失敗したログを再度キューに戻す
          logs.forEach((log) => this.addToBatch(log));
        } else {
          this.logger.debug(
            { logCount: logs.length },
            'Successfully processed rate limit log batch',
          );
        }
      } catch (error) {
        this.logger.error({ error }, 'Batch processing error');
        // 失敗したログを再度キューに戻す
        logs.forEach((log) => this.addToBatch(log));
      }
    });
  }

  async cleanup(): Promise<void> {
    // バッチタイマーの停止
    if (this.batchTimer) {
      clearInterval(this.batchTimer);
    }

    // 残りのログを処理
    await this.processBatch();
    await this.batchQueue.onIdle();

    // 古いログの削除
    const cutoffDate = new Date();
    cutoffDate.setDate(cutoffDate.getDate() - 1); // 1日以上前のログを削除

    try {
      const { error } = await this.supabase
        .from('rate_limit_logs')
        .delete()
        .lt('window_start', cutoffDate.toISOString());

      if (error) {
        this.logger.error({ error }, 'Failed to clean up old rate limit logs');
      }
    } catch (error) {
      this.logger.error({ error }, 'Cleanup error');
    }
  }
}
```

### レート制限メトリクスコレクター

```typescript
// src/infrastructure/monitoring/rate-limit-metrics.ts
import { injectable, inject } from 'tsyringe';
import { DI_TOKENS } from '@/infrastructure/di/tokens';
import { Logger } from 'pino';
import { Counter, Histogram, Registry } from 'prom-client';

@injectable()
export class RateLimitMetrics {
  private readonly requestCounter: Counter<string>;
  private readonly rateLimitHits: Counter<string>;
  private readonly windowSizeHistogram: Histogram<string>;

  constructor(
    @inject(DI_TOKENS.MetricsRegistry)
    private readonly registry: Registry,
    @inject(DI_TOKENS.Logger)
    private readonly logger: Logger,
  ) {
    this.requestCounter = new Counter({
      name: 'api_rate_limit_requests_total',
      help: 'Total number of rate limit checks',
      labelNames: ['endpoint', 'tier', 'result'],
      registers: [registry],
    });

    this.rateLimitHits = new Counter({
      name: 'api_rate_limit_exceeded_total',
      help: 'Total number of rate limit exceeded events',
      labelNames: ['endpoint', 'tier'],
      registers: [registry],
    });

    this.windowSizeHistogram = new Histogram({
      name: 'api_rate_limit_window_size',
      help: 'Distribution of request counts per window',
      labelNames: ['endpoint', 'tier'],
      buckets: [1, 5, 10, 25, 50, 100, 250, 500, 1000],
      registers: [registry],
    });
  }

  recordRequest(endpoint: string, tier: string, allowed: boolean, windowSize: number): void {
    const result = allowed ? 'allowed' : 'blocked';

    this.requestCounter.inc({
      endpoint,
      tier,
      result,
    });

    if (!allowed) {
      this.rateLimitHits.inc({
        endpoint,
        tier,
      });
    }

    this.windowSizeHistogram.observe({ endpoint, tier }, windowSize);
  }

  async getMetrics(): Promise<string> {
    return this.registry.metrics();
  }
}
```

### 並行性テスト

```typescript
// src/infrastructure/services/__tests__/rate-limit-concurrency.test.ts
import { RateLimitLogService } from '../rate-limit-log.service';
import { UserId } from '@/domain/auth/value-objects/user-id';
import { UserTier } from '@/domain/auth/value-objects/user-tier';

describe('RateLimitLogService Concurrency', () => {
  let service: RateLimitLogService;
  const userId = UserId.generate();
  const tier = UserTier.create('tier1').getValue();
  const endpoint = '/api/data/test.json';

  beforeEach(() => {
    service = new RateLimitLogService(mockSupabase, mockLogger);
  });

  afterEach(async () => {
    await service.cleanup();
  });

  it('should handle concurrent requests correctly', async () => {
    const concurrentRequests = 100;
    const promises: Promise<any>[] = [];

    // 100個の並行リクエストを送信
    for (let i = 0; i < concurrentRequests; i++) {
      promises.push(service.checkAndLog(userId, endpoint, tier));
    }

    const results = await Promise.all(promises);

    // tier1のレート制限は60/分
    const allowed = results.filter((r) => r.getValue().allowed).length;
    const blocked = results.filter((r) => !r.getValue().allowed).length;

    expect(allowed).toBeLessThanOrEqual(60);
    expect(blocked).toBe(concurrentRequests - allowed);
  });

  it('should not lose requests during batch processing', async () => {
    const requestCount = 1000;
    const promises: Promise<any>[] = [];

    // 大量のリクエストを短時間で送信
    for (let i = 0; i < requestCount; i++) {
      promises.push(
        service.checkAndLog(
          UserId.generate(), // 異なるユーザー
          endpoint,
          tier,
        ),
      );

      // ランダムな遅延を追加
      if (i % 10 === 0) {
        await new Promise((resolve) => setTimeout(resolve, 1));
      }
    }

    await Promise.all(promises);

    // バッチ処理が完了するまで待機
    await new Promise((resolve) => setTimeout(resolve, 500));

    // データベースに記録されたログ数を確認
    const { data } = await mockSupabase.from('rate_limit_logs').select('*');

    expect(data.length).toBeGreaterThan(0);
  });
});
```

### データベースインデックスの最適化

```sql
-- レート制限ログ用の追加インデックス
CREATE INDEX CONCURRENTLY idx_rate_limit_composite
  ON rate_limit_logs(user_id, endpoint, window_start DESC);

-- パーティショニング設定（大規模な場合）
CREATE TABLE rate_limit_logs_partitioned (
  LIKE rate_limit_logs INCLUDING ALL
) PARTITION BY RANGE (window_start);

-- 日次パーティションの作成
CREATE TABLE rate_limit_logs_2025_01_01
  PARTITION OF rate_limit_logs_partitioned
  FOR VALUES FROM ('2025-01-01') TO ('2025-01-02');
```
